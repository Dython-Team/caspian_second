{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atefe_hjn97/Documents/VScode/caspian_second/CASPIAN_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.nonparametric.smoothers_lowess import lowess\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import shap\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from feature_mapping import *\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = pd.read_csv('../casp 5/cleaned_casp5_boy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5 = df_5.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       46.000000\n",
       "1       34.900002\n",
       "2       49.000000\n",
       "3       87.699997\n",
       "4       77.500000\n",
       "          ...    \n",
       "7080    22.000000\n",
       "7081    36.299999\n",
       "7082    58.000000\n",
       "7083    34.299999\n",
       "7084    29.299999\n",
       "Name: weight, Length: 7085, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.metrics import mutual_info_score\n",
    "import matplotlib.pyplot as plt\n",
    "def split_X_y(df_org, threshold=0.5):\n",
    "    df = df_org.copy()\n",
    "    X = df.drop(columns=['bmi','age','diastoli','weight','height','waist','wrist','hip','systolic',\n",
    "                          'catage','bmi_category'], axis=1)\n",
    "    y = df['bmi_category']\n",
    "    print('X: ',X.shape)\n",
    "    print('y: ',y.shape)\n",
    "    mi_matrix = np.zeros((X.shape[1], X.shape[1]))\n",
    "    for i in range(X.shape[1]):\n",
    "        for j in range(X.shape[1]):\n",
    "            mi_matrix[i, j] = mutual_info_score(X.iloc[:, i], X.iloc[:, j])\n",
    "\n",
    "    mi_df = pd.DataFrame(mi_matrix, index=X.columns, columns=X.columns)\n",
    "\n",
    "    # Apply threshold: Remove values below threshold\n",
    "    mi_df[mi_df < threshold] = np.nan\n",
    "\n",
    "    # Drop rows & columns where all values are NaN\n",
    "    mi_df = mi_df.dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "\n",
    "    # Plot Heatmap if there's remaining data\n",
    "    if not mi_df.empty:\n",
    "        plt.figure(figsize=(max(8, len(mi_df) * 0.5), max(8, len(mi_df) * 0.5)))  # Dynamic size\n",
    "        sns.heatmap(mi_df, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "        plt.title(f\"Filtered Mutual Information Heatmap (Threshold: {threshold})\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No mutual information values above the threshold.\")\n",
    "    # Calculate mutual information\n",
    "    # mi_scores = mutual_info_classif(X, 'sleep_hours_friday')\n",
    "\n",
    "    # # Create a Series with feature names and their MI scores\n",
    "    # mi_series = pd.Series(mi_scores, index=X.columns, name='Mutual Information')\n",
    "\n",
    "    # # Sort the Series for better interpretation\n",
    "    # mi_series = mi_series.sort_values(ascending=False)\n",
    "\n",
    "    # # Plot MI scores\n",
    "    # mi_series.plot.bar(figsize=(10, 10))\n",
    "    # plt.title(\"Mutual Information Scores\")\n",
    "    # plt.ylabel(\"Mutual Information\")\n",
    "    # plt.show()\n",
    "\n",
    "    return X, y,mi_df\n",
    "def standardize_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)  # Fit on training data and transform\n",
    "    X_test_scaled = scaler.transform(X_test)        # Only transform test data\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_catboost(X_train, y_train, iterations=200, random_state=42, learning_rate=0.1, depth=10, l2_leaf_reg=3, bagging_temperature=1):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=iterations, \n",
    "        random_seed=random_state, \n",
    "        verbose=0, \n",
    "        learning_rate=learning_rate, \n",
    "        depth=depth, \n",
    "        l2_leaf_reg=l2_leaf_reg, \n",
    "        bagging_temperature=bagging_temperature\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, iterations\n",
    "\n",
    "def train_xgboost(X_train, y_train, iterations=200, random_state=42, learning_rate=0.1, max_depth=10, alpha=0, gamma=0):\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=iterations,  # Number of boosting rounds\n",
    "        random_state=random_state, \n",
    "        learning_rate=learning_rate, \n",
    "        max_depth=max_depth, \n",
    "        alpha=alpha,  # L2 regularization term on weights\n",
    "        gamma=gamma,  # Minimum loss reduction required to make a further partition\n",
    "        verbosity=0  # Set verbosity to 0 to suppress messages\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    return model, iterations\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Classification Report:\", report)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "    return {\"accuracy\": accuracy, \"report\": report, \"confusion_matrix\": cm}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# def plot_confusion_matrix(confusion_mat, class_names, title=\"Confusion Matrix\"):\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "#     plt.xlabel(\"Predicted Labels\")\n",
    "#     plt.ylabel(\"True Labels\")\n",
    "#     plt.title(title)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def perform_rfecv(X,y):\n",
    "    xgb_model = XGBClassifier(\n",
    "        n_estimators=200, \n",
    "        random_state=42, \n",
    "        learning_rate=0.1, \n",
    "        max_depth=10, \n",
    "        alpha=0, \n",
    "        gamma=0, \n",
    "        verbosity=0\n",
    "    )\n",
    "    scorer = make_scorer(f1_score, average='weighted')  \n",
    "    selector = RFECV(estimator=xgb_model, step=1, cv=5, scoring=scorer,min_features_to_select=20)\n",
    "    selector.fit(X, y)\n",
    "    selected_features = X.columns[selector.support_]\n",
    "    return selected_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def undersample_data(X, y):\n",
    "    majority_class = y.value_counts().idxmax()\n",
    "    majority_class_size = y.value_counts().max()\n",
    "    majority_class_new_size = majority_class_size // 3\n",
    "    undersampling_strategy = {majority_class: majority_class_new_size}\n",
    "    rus = RandomUnderSampler(sampling_strategy=undersampling_strategy, random_state=42)\n",
    "    return rus.fit_resample(X, y)\n",
    "\n",
    "def resample_data(X_train, y_train, method=None):\n",
    "    if method == \"oversample\":\n",
    "        ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "        return ros.fit_resample(X_train, y_train)\n",
    "    elif method == \"adasyn\":\n",
    "        adasyn = ADASYN(sampling_strategy='auto', random_state=42)\n",
    "        return adasyn.fit_resample(X_train, y_train)\n",
    "    elif method == \"smote\":\n",
    "        smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "        return smote.fit_resample(X_train, y_train)\n",
    "    return X_train, y_train  # No resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import ADASYN  # Import ADASYN\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def process_and_train_model_for_each_age(df, catage, k=20):\n",
    "    results = []\n",
    "    selected_features_total = []\n",
    "    shap_values = None  \n",
    "    X_train_selected = None  \n",
    "\n",
    "    for cat in catage:\n",
    "        df_age = df[df['catage'] == cat]\n",
    "        # df_age = df\n",
    "        if df_age.empty:\n",
    "            continue\n",
    "        X, y,mutual_inf = split_X_y(df_age)\n",
    "        mutual_inf.to_csv('mutual_info.csv')\n",
    "        # selected_features = perform_rfecv(X,y)\n",
    "        # X_selected = X[selected_features]\n",
    "        X_selected = X\n",
    "        # Now, X_selected contains only the selected features\n",
    "        print(X_selected.shape)\n",
    "        # print(len(selected_features))\n",
    "        # print(\"Selected Features:\", list(selected_features))\n",
    "\n",
    "        print(f\"Class distribution before undersampling for age {cat}:\")\n",
    "        print(pd.Series(y).value_counts())\n",
    "        X_resampled, y_resampled = undersample_data(X_selected, y)\n",
    "        print(f\"Class distribution after undersampling for age {cat}:\")\n",
    "        print(pd.Series(y_resampled).value_counts())\n",
    "\n",
    "        # Train-test split first, before resampling\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42)\n",
    "        # Print the class distribution before resampling\n",
    "        print(f\"Train Class distribution before resampling for age {cat}:\")\n",
    "        print(y_train.value_counts())\n",
    "\n",
    "        X_train_resampled,y_train_resampled = resample_data(X_train,y_train)\n",
    "        print(f\"Class distribution after resampling for age {cat}:\")\n",
    "        print(pd.Series(y_train_resampled).value_counts())\n",
    "\n",
    "        # Standardize the data\n",
    "        X_train_scaled, X_test_scaled = standardize_data(X_train_resampled, X_test)\n",
    "        print(type(X_train_scaled))\n",
    "        # Convert scaled data back to DataFrame to retain feature names\n",
    "        # X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train_resampled.index)\n",
    "        # X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)\n",
    "        # Define the model for feature selection\n",
    "        \n",
    "        # Train the model with the resampled (or original) data\n",
    "        catboost_model, iterations = train_xgboost(X_train_scaled, y_train_resampled)\n",
    "        catboost_metrics = evaluate_model(catboost_model, X_test_scaled, y_test)\n",
    "\n",
    "        # Append results\n",
    "        results.append({\n",
    "            \"catage\": cat,\n",
    "            \"accuracy\": catboost_metrics['accuracy'],\n",
    "            \"num_samples\": len(df_age),\n",
    "            \"classification_report\": catboost_metrics['report']\n",
    "        })\n",
    "        # selected_features_total.append(selected_features)\n",
    "        # Plot confusion matrix\n",
    "        class_names = list(np.unique(y))  # Ensure unique class labels\n",
    "        # plot_confusion_matrix(catboost_metrics['confusion_matrix'], class_names, title=f\"Confusion Matrix (Age {cat})\")\n",
    "\n",
    "    return results,selected_features_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catage = df_5['catage'].unique()\n",
    "catage = [0,1,2]\n",
    "results,selected_features_total = process_and_train_model_for_each_age(df_5, catage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age0_features = ['spent_time_friend1', 'lunch_routinday', 'saltysnack', 'vegetables', 'milk', 'fastfoods', 'physical_activity_hour', 'physical_activity', 'TV_watching_routinday', 'TV_watching_friday', 'sleep_hours_routinday', 'sleep_hours_friday', 'fight_number', 'father_hookah', 'sibling_smoker', 'confusion_number', 'insomnia_number', 'back_pain_number', 'worried_number', 'anxiety_number', 'smoke_escaping_problems', 'smoke_focus', 'birth_weight', 'breast_feeding_duration', 'grains', 'liverandkalepache', 'bread', 'potato', 'friedfoods', 'fresh_fruit_nondaily', 'litigant_friend', 'litigant_parent', 'comfort_mother_nadaram', 'comfort_father_nadaram', 'comfort_sister_rahati', 'father_edu_father died', 'father_edu_graduate education', 'father_edu_illiterate', 'father_edu_intermediate', 'mother_edu_illiterate', 'father_job_unemployed', 'mother_job_farmer', 'mother_job_housewife', 'mother_job_others', 'school_type_public school', \"milk_type_mother's milk and cow's milk\", \"milk_type_mother's milk and powdered milk\", 'milk_type_powdered milk', 'bread_type_whole grain bread', 'oil_type_cooking oil', 'oil_type_lamb fat', 'dairy_type_pasteurized low-fat', 'diet_plan_no, but it should be reduced', 'diet_plan_weight is fine']\n",
    "age1_features = ['catage','close_friend_count', 'spent_time_friend1', 'spent_time_friend2', 'chatting_online', 'breakfast_routindays', 'lunch_routinday', 'dinner_friday', 'saltysnack', 'milk', 'fastfoods', 'TV_watching_routinday', 'TV_watching_friday', 'computer_work_friday', 'sleep_hours_routinday', 'sleep_hours_friday', 'fight_number', 'carry_weapons', 'bully_number', 'father_hookah', 'sibling_hookah', 'others_hookah', 'father_smoker', 'confusion_number', 'worthless_number', 'back_pain_number', 'headache_number', 'worried_number', 'stomach_ache_number', 'smoke_feeling_grown_up', 'family_size', 'livingparent', 'birth_weight', 'breast_feeding_duration', 'potato', 'reduce_fast_food', 'comfort_friend_nadaram', 'comfort_brother_rahati', 'home_ownership_personal', 'home_ownership_rented', 'father_edu_diploma', 'mother_edu_diploma', 'mother_edu_illiterate', 'mother_edu_mother died', 'mother_job_housewife', 'mother_job_no job', \"milk_type_mother's milk and powdered milk\", 'complementary_feeding_homemade food', 'complementary_feeding_ready-made food', 'oil_type_cooking oil', 'dairy_type_pasteurized full-fat', 'region_urban', 'diet_plan_no, but it should be reduced', 'diet_plan_weight is fine', 'diet_plan_yes']\n",
    "age2_features = ['close_friend_count', 'spent_time_friend1', 'spent_time_friend2', 'breakfast_routindays', 'breakfast_friday', 'lunch_routinday', 'lunch_friday', 'dinner_routinday', 'sweet', 'saltysnack', 'soda', 'dry_fruit', 'fresh_juice', 'packed_juice', 'vegetables', 'milk', 'fastfoods', 'physical_activity_hour', 'physical_activity', 'TV_watching_routinday', 'TV_watching_friday', 'computer_work_routinday', 'computer_work_friday', 'sleep_hours_routinday', 'sleep_hours_friday', 'injury_number', 'fight_number', 'carry_weapons', 'victim_number', 'bully_number', 'mother_hookah', 'father_hookah', 'sibling_hookah', 'others_hookah', 'father_smoker', 'mother_smoker', 'others_smoker', 'confusion_number', 'worthless_number', 'insomnia_number', 'back_pain_number', 'headache_number', 'worried_number', 'stomach_ache_number', 'angriness_number', 'anxiety_number', 'mental_health_overview', 'smoke_escaping_problems', 'smoke_feeling_grown_up', 'smoke_staying_awake', 'smoke_feeling_loved', 'family_size', 'car_ownership', 'computer_ownership', 'livingparent', 'birth_weight', 'breast_feeding_duration', 'fatty_dairy', 'usual_dairy', 'meat', 'liverandkalepache', 'bread', 'rice', 'potato', 'friedfoods', 'fruit_nut_substitute', 'reduce_fast_food', 'increase_vegetables', 'reduce_salt', 'reduce_fat', 'use_liquid_oil', 'injury_parent_ask', 'fresh_fruit_nondaily', 'litigant_stranger', 'comfort_friend_nadaram', 'comfort_friend_rahati', 'comfort_father_rahati', 'comfort_sister_nadaram', 'home_ownership_personal', 'home_ownership_rented', 'father_edu_diploma', 'father_edu_elementry education', 'father_edu_father died', 'father_edu_graduate education', 'father_edu_illiterate', 'father_edu_intermediate', 'mother_edu_diploma', 'mother_edu_elementry education', 'mother_edu_graduate education', 'mother_edu_illiterate', 'mother_edu_intermediate', 'father_job_farmer', 'father_job_no job', 'father_job_self-employed', 'father_job_unemployed', 'mother_job_housewife', 'mother_job_others', 'school_type_public school', \"milk_type_mother's milk\", \"milk_type_mother's milk and cow's milk\", \"milk_type_mother's milk and powdered milk\", 'complementary_feeding_homemade food', 'complementary_feeding_ready-made food', 'bread_type_whole grain bread', 'oil_type_cooking oil', 'oil_type_solid oil', 'dairy_type_non-pasteurized regular', 'dairy_type_pasteurized full-fat', 'dairy_type_pasteurized low-fat', 'region_urban', 'depression_no', 'diet_plan_no, but it should be reduced', 'diet_plan_yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = list(set(age1_features) & set(age0_features))\n",
    "print(intersection)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CASPIAN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
