{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load and preprocess datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_v_new = pd.read_spss('data/caspian-5.sav',convert_categoricals=True)\n",
    "df_v = pd.read_spss('data/last-caspian-v.sav',convert_categoricals=True) \n",
    "df_iv = pd.read_spss('data/caspian4_.sav',convert_categoricals=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13983, 411)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13983"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_v_new.id2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sorted(df_iv['University'].unique(), key=str)\n",
    "b = sorted(df_v_new['University'].unique(), key=str)\n",
    "\n",
    "# Compare the sorted lists\n",
    "with open('new_5.txt', \"w\") as file:\n",
    "      for item, ite in zip(a, b):  # Iterate over both a and b at the same time\n",
    "        file.write(f'{item}\\t{ite}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= df_v_new.University.unique().sort_values()\n",
    "b= df_v.universi.unique().sort_values()\n",
    "with open('new_5.txt', \"w\") as file:\n",
    "    for item in a: # Iterate over both a and b at the same time\n",
    "        file.write(f'{item}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id2', 'university', 'region', 'cluster', 'cross', 'birth_ye',\n",
       "       'sample_c', 'a_1', 'a_2', 'a_3',\n",
       "       ...\n",
       "       'difficul', 'feelingd', 'multiple', 'tstmvpa', 'tyg', 'lunchcon',\n",
       "       'dinnerco', 'lunchski', 'dinnersk', 'agebinar'],\n",
       "      dtype='object', length=506)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iv_prev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records with NaN value in weight or height in caspian_IV_prev: 138\n",
      "Number of records with NaN value in weight or height in caspian_IV: 143\n",
      "Number of records with NaN value in weight or height in caspian_V: 128\n",
      "Number of records with NaN value in weight or height in caspian_V_new: 143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19397/1103639069.py:402: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  processed_dfs['caspian_V']['university'] = processed_dfs['caspian_V']['university'].replace(university_to_province)\n",
      "/tmp/ipykernel_19397/1103639069.py:411: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  processed_dfs['caspian_IV_prev']['university'] = processed_dfs['caspian_IV_prev']['university'].replace(university_to_province)\n",
      "/tmp/ipykernel_19397/1103639069.py:420: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  processed_dfs['caspian_V_new']['university'] = processed_dfs['caspian_V_new']['university'].replace(university_to_province)\n"
     ]
    }
   ],
   "source": [
    "df_iv = pd.read_spss('data/caspian4_.sav',convert_categoricals=True)\n",
    "df_iv_prev = pd.read_spss('data/last-caspian-IV(1).sav',convert_categoricals=True)\n",
    "df_v = pd.read_spss('data/last-caspian-v.sav',convert_categoricals=True) \n",
    "df_v_new = pd.read_spss('data/caspian-5.sav',convert_categoricals=True)\n",
    "def rename_features(df1, caspian_number):\n",
    "    df2 = df1.copy()\n",
    "    # Rename the features in the dataframe\n",
    "    if caspian_number == 55:\n",
    "        df2.rename(columns={'weight_1': 'weight', 'height_2': 'height', 'University': 'university','ap_9':'schoolType'}, inplace=True)\n",
    "    if caspian_number == 5:\n",
    "        df2.rename(columns={'weight_1': 'weight', 'height_2': 'height', 'universi': 'university','ap_9':'schoolType'}, inplace=True)\n",
    "    elif caspian_number == 4:\n",
    "        df2.rename(columns={'weight_1': 'weight', 'height_2': 'height', 'universi': 'university','ap_9':'schoolType'}, inplace=True)\n",
    "        df2.drop('sex', axis=1, inplace=True)\n",
    "        # print(df2.columns)\n",
    "        df2.rename(columns={'sex2': 'sex', 'weight_1': 'weight', 'height_2': 'height', 'University': 'university','ap_9':'schoolType'}, inplace=True)\n",
    "    elif caspian_number == 3:\n",
    "        df2.rename(columns={'weighte': 'weight', 'heighte': 'height', 'province': 'university', 'area':'region','p9':'schoolType'}, inplace=True)\n",
    "    elif caspian_number == 1:\n",
    "        df2.columns = df2.columns.str.lower()\n",
    "        df2.rename(columns={'univer': 'university','district':'region', 'schoolty':'schoolType'}, inplace=True)\n",
    "        \n",
    "\n",
    "    return df2\n",
    "\n",
    "df_iv = rename_features(df_iv, 4)\n",
    "df_iv_prev = rename_features(df_iv_prev, 4)\n",
    "\n",
    "df_v = rename_features(df_v, 5)\n",
    "df_v_new = rename_features(df_v_new, 55)\n",
    "\n",
    "# Apply transformations to 'df_iv' and 'df_v'\n",
    "df_iv['sex'] = df_iv['sex'].apply(lambda x: 'Girl' if x == 'girl' else 'Boy' if x == 'boy' else x)\n",
    "df_iv['schoolType'] = df_iv['schoolType'].apply(lambda x: 'Public School' if x == 'dolati' else 'Private School' if x == 'gheyre entef' else 'Unknown')\n",
    "df_v['schoolType'] = df_v['schoolType'].apply(lambda x: 'Public School' if x == 'dolati' else 'Private School' if x == 'gheyre entefai' else 'Unknown')\n",
    "df_v_new['schoolType'] = df_v_new['schoolType'].apply(lambda x: 'Public School' if x == 'dolati' else 'Private School' if x == 'gheyre entefai' else 'Unknown')\n",
    "df_v_new['sex'] = df_v_new['sex'].apply(lambda x: 'Girl' if x == 'girl' else 'Boy' if x == 'boy' else x)\n",
    "\n",
    "# Now define df_dict with the modified dataframes\n",
    "df_dict = {'caspian_IV_prev':df_iv_prev,'caspian_IV': df_iv, 'caspian_V': df_v,'caspian_V_new':df_v_new}\n",
    "\n",
    "def preprocess(dataframes_dict):\n",
    "    processed_dfs = {}  # Dictionary to store processed DataFrames\n",
    "    for name, df_org in dataframes_dict.items():\n",
    "        df = df_org.copy()\n",
    "\n",
    "        # Filter age\n",
    "        df = df[(df[\"age\"] >= 7) & (df[\"age\"] <= 18)]\n",
    "        # please change the type of heught_1 and weight_1 in caspian4 to numeric if you can't do it directly uncomment two line below\n",
    "        df['height'] = pd.to_numeric(df['height'], errors='coerce')\n",
    "        df['weight'] = pd.to_numeric(df['weight'], errors='coerce')\n",
    "        df[\"bmi1\"] = df[\"weight\"] / ((df[\"height\"] / 100) ** 2)\n",
    "        \n",
    "        # Remove null tuples\n",
    "        records_with_nulls = df[\n",
    "            df[[\"weight\", \"height\", \"sex\", \"age\"]].isna().any(axis=1)\n",
    "        ]\n",
    "        df = df.dropna(subset=[\"height\", \"weight\", \"sex\"])\n",
    "        print(\n",
    "            f\"Number of records with NaN value in weight or height in {name}: {len(records_with_nulls)}\"\n",
    "        )\n",
    "\n",
    "        # Store the processed DataFrame in the new dictionary\n",
    "        processed_dfs[name] = df\n",
    "\n",
    "    return processed_dfs\n",
    "\n",
    "\n",
    "# Usage\n",
    "processed_dfs = preprocess(df_dict)\n",
    "\n",
    "# Define the mapping dictionary\n",
    "replacement_map = {\n",
    "    '1 or 2 in we': '1 or 2 in week',\n",
    "    '3 or 4 in we': '3 or 4 in week',\n",
    "    '5 or 6 in we': '5 or 6 in week',\n",
    "    'never': 'never',\n",
    "    'everyday': 'everyday',\n",
    "    '': np.nan  # map empty strings to NaN\n",
    "}\n",
    "replacement_ap_3= {\n",
    "    'diplome': 'diplome',\n",
    "    'bachelor': 'Bachelor',\n",
    "    'primary': 'primary',\n",
    "    'upper than b': 'upper than bachelor',\n",
    "    '': np.nan,  # Empty string replaced by NaN\n",
    "    'intermediate': 'intermediate',\n",
    "    'illiterate': 'illiterate',\n",
    "    'father died': 'Father died',\n",
    "    'quranic lite': 'Quranic Literacy',\n",
    "    'upper than bachelor':'upper than bachelor',\n",
    "    'quranic literacy':'Quranic Literacy',\n",
    "    'mother died' :'mother died'\n",
    "}\n",
    "\n",
    "\n",
    "# Apply the mapping to 'a_4' column, using the default value of an empty string\n",
    "processed_dfs['caspian_IV']['a_4'] = processed_dfs['caspian_IV']['a_4'].apply(lambda x: replacement_map.get(x, ''))\n",
    "processed_dfs['caspian_IV']['ap_3'] = processed_dfs['caspian_IV']['ap_3'].apply(lambda x: replacement_ap_3.get(x, ''))\n",
    "processed_dfs['caspian_IV']['ap_4'] = processed_dfs['caspian_IV']['ap_4'].apply(lambda x: replacement_ap_3.get(x, ''))\n",
    "processed_dfs['caspian_IV_prev']['ap_3'] = processed_dfs['caspian_IV_prev']['ap_3'].apply(lambda x: replacement_ap_3.get(x, ''))\n",
    "processed_dfs['caspian_IV_prev']['ap_4'] = processed_dfs['caspian_IV_prev']['ap_4'].apply(lambda x: replacement_ap_3.get(x, ''))\n",
    "processed_dfs['caspian_IV'].replace('', np.nan, inplace=True)\n",
    "processed_dfs['caspian_V'].replace('', np.nan, inplace=True)\n",
    "\n",
    "def replacement_function(df_dict, mappings):\n",
    "    # Loop over each dataset in the dictionary\n",
    "    for name, df in df_dict.items():\n",
    "        # Get the appropriate mapping for each Caspian dataset\n",
    "        university_to_province = mappings.get(name)\n",
    "        if university_to_province:\n",
    "    # Iterate over each DataFrame in df_dict\n",
    "            for name, df in df_dict.items():\n",
    "                # Replace values based on the mapping\n",
    "                df_dict[name] = df.copy()  # Work with a copy if needed\n",
    "                df_dict[name]['university'] = df_dict[name]['university'].replace(university_to_province)\n",
    "                \n",
    "                # Ensure the 'university' column is of type string\n",
    "                df_dict[name]['university'] = df_dict[name]['university'].astype(str)\n",
    "                \n",
    "                # Sort the DataFrame by the 'university' column\n",
    "                df_dict[name] = df_dict[name].sort_values(by='university', ascending=True)\n",
    "        \n",
    "        return df_dict\n",
    "\n",
    "    # return df_dict\n",
    "\n",
    "# # Define your mappings dictionary for each Caspian dataset\n",
    "mappings = {\n",
    "    'caspian_I': {\n",
    "        \"Gorgan\": \"Golestan\",\n",
    "        \"Mashad\": \"Razavi Khorasan\",\n",
    "        \"ShahidBeheshti\": \"Tehran\",\n",
    "        \"Tabriz\": \"East Azerbaijan\",\n",
    "        \"Yazd\": \"Yazd\",\n",
    "        \"Rasht\": \"Gilan\"\n",
    "    },\n",
    "    'caspian_III': {\n",
    "        \"4mahal bakhtyari\": \"Chaharmahal and Bakhtiari\",\n",
    "        \"ardebil\": \"Ardabil\",\n",
    "        \"azar gharbi\": \"West Azerbaijan\",\n",
    "        \"boshehr\": \"Bushehr\",\n",
    "        \"esfahan\": \"Isfahan\",\n",
    "        \"fars\": \"Fars\",\n",
    "        \"gazvin\": \"Qazvin\",\n",
    "        \"gilan\": \"Gilan\",\n",
    "        \"golestan\": \"Golestan\",\n",
    "        \"gom\": \"Qom\",\n",
    "        \"hamedan\": \"Hamedan\",\n",
    "        \"hormozgan\": \"Hormozgan\",\n",
    "        \"ilam\": \"Ilam\",\n",
    "        \"kerman\": \"Kerman\",\n",
    "        \"kermanshah\": \"Kermanshah\",\n",
    "        \"khorasan jonobi\": \"South Khorasan\",\n",
    "        \"khorasan razavi\": \"Razavi Khorasan\",\n",
    "        \"khorasan shomali\": \"North Khorasan\",\n",
    "        \"khozestan\": \"Khuzestan\",\n",
    "        \"kordestan\": \"Kurdistan\",\n",
    "        \"lorestan\": \"Lorestan\",\n",
    "        \"markazi\": \"Markazi\",\n",
    "        \"mazandaran\": \"Mazandaran\",\n",
    "        \"semnan\": \"Semnan\",\n",
    "        \"tehran\": \"Tehran\",\n",
    "        \"yazd\": \"Yazd\",\n",
    "        \"zanjan\": \"Zanjan\"\n",
    "    },\n",
    "    'caspian_IV': {\n",
    "        'charmahal': 'Chaharmahal and Bakhtiari',\n",
    "        'alborz': 'Alborz',\n",
    "        'dezful': 'Khuzestan',\n",
    "        'mazandaran': 'Mazandaran',\n",
    "        'sabzevar': 'Razavi Khorasan',\n",
    "        'azar gharbi': 'West Azerbaijan',\n",
    "        'kurdestan': 'Kurdistan',\n",
    "        'kerman.jirof': 'Kerman',\n",
    "        'ardebil': 'Ardabil',\n",
    "        'hamedan': 'Hamedan',\n",
    "        'khorasan sho': 'South Khorasan',\n",
    "        'ilam': 'Ilam',\n",
    "        'khozestan': 'Khuzestan',\n",
    "        'shoshtar': 'Khuzestan',\n",
    "        'qazvin': 'Qazvin',\n",
    "        'isfahan': 'Isfahan',\n",
    "        'gilan': 'Gilan',\n",
    "        'tabriz': 'East Azerbaijan',\n",
    "        'arak': 'Markazi',\n",
    "        'semnan': 'Semnan',\n",
    "        'hormozgan': 'Hormozgan',\n",
    "        'lorestan': 'Lorestan',\n",
    "        'boshehr': 'Bushehr',\n",
    "        'zanjan': 'Zanjan',\n",
    "        'sistan': 'Sistan and Baluchestan',\n",
    "        'kermanshah': 'Kermanshah',\n",
    "        'fars': 'Fars',\n",
    "        'torbat heida': 'Razavi Khorasan',\n",
    "        'kerman': 'Kerman',\n",
    "        'khorasan jon': 'North Khorasan',\n",
    "        'yazd': 'Yazd',\n",
    "        'golestan': 'Golestan',\n",
    "        'behbahan': 'Khuzestan',\n",
    "        'shahidbehesh': 'Tehran',\n",
    "        'shahrood': 'Semnan',\n",
    "        'khorasan raz': 'Razavi Khorasan',\n",
    "        'saveh': 'Markazi',\n",
    "        'iran': 'General Iran',\n",
    "        'esfarayen': 'North Khorasan',\n",
    "        'kohkiloyeh': 'Kohgiluyeh and Boyer-Ahmad',\n",
    "        'abadan': 'Khuzestan',\n",
    "        'rafsanjan': 'Kerman',\n",
    "        'iranshahr': 'Sistan and Baluchestan',\n",
    "        'babol': 'Mazandaran',\n",
    "        'torbat jam': 'Razavi Khorasan',\n",
    "        'zabol': 'Sistan and Baluchestan',\n",
    "        'kashan': 'Isfahan',\n",
    "        'jahrom': 'Fars',\n",
    "        'neishabor': 'Razavi Khorasan',\n",
    "        'bam': 'Kerman',\n",
    "        'tehran': 'Tehran',\n",
    "        'larestan': 'Fars',\n",
    "        'fasad': 'Fars'\n",
    "    },\n",
    "    'caspian_IV_prev':{\n",
    "        \"abadan\": \"Khuzestan\",\n",
    "        \"alborz\": \"Alborz\",\n",
    "        \"arak\": \"Markazi\",\n",
    "        \"ardebil\": \"Ardabil\",\n",
    "        \"azar gharbi\": \"West Azerbaijan\",\n",
    "        \"babol\": \"Mazandaran\",\n",
    "        \"bam\": \"Kerman\",\n",
    "        \"behbahan\": \"Khuzestan\",\n",
    "        \"boshehr\": \"Bushehr\",\n",
    "        \"charmahal\": \"Chaharmahal and Bakhtiari\",\n",
    "        \"dezful\": \"Khuzestan\",\n",
    "        \"esfarayen\": \"North Khorasan\",\n",
    "        \"fars\": \"Fars\",\n",
    "        \"fasad\": \"Fars\",\n",
    "        \"gilan\": \"Gilan\",\n",
    "        \"golestan\": \"Golestan\",\n",
    "        \"hamedan\": \"Hamedan\",\n",
    "        \"hormozgan\": \"Hormozgan\",\n",
    "        \"ilam\": \"Ilam\",\n",
    "        \"iran\": \"General Iran\",  # Special case: general reference\n",
    "        \"iranshahr\": \"Sistan and Baluchestan\",\n",
    "        \"isfahan\": \"Isfahan\",\n",
    "        \"jahrom\": \"Fars\",\n",
    "        \"kashan\": \"Isfahan\",\n",
    "        \"kerman\": \"Kerman\",\n",
    "        \"kerman.jiroft\": \"Kerman\",\n",
    "        \"kermanshah\": \"Kermanshah\",\n",
    "        \"khorasan jonobi\": \"South Khorasan\",\n",
    "        \"khorasan razavi\": \"Razavi Khorasan\",\n",
    "        \"khorasan shomali\": \"North Khorasan\",\n",
    "        \"khozestan\": \"Khuzestan\",\n",
    "        \"kohkiloyeh\": \"Kohgiluyeh and Boyer-Ahmad\",\n",
    "        \"kurdestan\": \"Kurdistan\",\n",
    "        \"larestan\": \"Fars\",\n",
    "        \"lorestan\": \"Lorestan\",\n",
    "        \"mazandaran\": \"Mazandaran\",\n",
    "        \"neishabor\": \"Razavi Khorasan\",\n",
    "        \"qazvin\": \"Qazvin\",\n",
    "        \"rafsanjan\": \"Kerman\",\n",
    "        \"sabzevar\": \"Razavi Khorasan\",\n",
    "        \"saveh\": \"Markazi\",\n",
    "        \"semnan\": \"Semnan\",\n",
    "        \"shahidbeheshti\": \"Tehran\",  # Assuming Shahid Beheshti University is in Tehran\n",
    "        \"shahrood\": \"Semnan\",\n",
    "        \"shoshtar\": \"Khuzestan\",\n",
    "        \"sistan\": \"Sistan and Baluchestan\",\n",
    "        \"tabriz\": \"East Azerbaijan\",\n",
    "        \"tehran\": \"Tehran\",\n",
    "        \"torbat heidariyeh\": \"Razavi Khorasan\",\n",
    "        \"torbat jam\": \"Razavi Khorasan\",\n",
    "        \"yazd\": \"Yazd\",\n",
    "        \"zabol\": \"Sistan and Baluchestan\",\n",
    "        \"zanjan\": \"Zanjan\"\n",
    "    },\n",
    "    'caspian_V': {\n",
    "        'tabriz': 'East Azerbaijan',\n",
    "        # None: 'Unknown',  # Assuming None corresponds to an unknown city\n",
    "        'azar gharbi': 'West Azerbaijan',\n",
    "        'ardebil': 'Ardabil',\n",
    "        'isfahan': 'Isfahan',\n",
    "        'kashan': 'Isfahan',\n",
    "        'alborz': 'Alborz',\n",
    "        'ilam': 'Ilam',\n",
    "        'boshehr': 'Bushehr',\n",
    "        'tehran': 'Tehran',\n",
    "        'Iran': 'General Iran',  # Assuming this is a general reference\n",
    "        'shahidbeheshti': 'Tehran',  # Assuming it's named after Shahid Beheshti University in Tehran\n",
    "        'charmahal': 'Chaharmahal and Bakhtiari',\n",
    "        'khorasan jonobi': 'South Khorasan',\n",
    "        'torbat heidariyeh': 'Razavi Khorasan',\n",
    "        'sabzevar': 'Razavi Khorasan',\n",
    "        'khorasan razavi': 'Razavi Khorasan',\n",
    "        'neishabor': 'North Khorasan',\n",
    "        'torbat jam': 'Razavi Khorasan',\n",
    "        'khorasan shomali': 'North Khorasan',\n",
    "        'esfarayen': 'North Khorasan',\n",
    "        'khozestan': 'Khuzestan',\n",
    "        'Abadan': 'Khuzestan',\n",
    "        'Behbahan': 'Khuzestan',\n",
    "        'Dezful': 'Khuzestan',\n",
    "        'Shoshtar': 'Khuzestan',\n",
    "        'Zanjan': 'Zanjan',\n",
    "        'Semnan': 'Semnan',\n",
    "        'Shahrood': 'Semnan',\n",
    "        'Zabol': 'Sistan and Baluchestan',\n",
    "        'Sistan': 'Sistan and Baluchestan',\n",
    "        'iranshahr': 'Sistan and Baluchestan',\n",
    "        'jahrom': 'Fars',\n",
    "        'fars': 'Fars',\n",
    "        'fasad': 'Fars',\n",
    "        'larestan': 'Fars',\n",
    "        'Qazvin': 'Qazvin',\n",
    "        'Kurdestan': 'Kurdistan',\n",
    "        'Kerman.jiroft': 'Kerman',\n",
    "        'Rafsanjan': 'Kerman',\n",
    "        'Kerman': 'Kerman',\n",
    "        'Bam': 'Kerman',\n",
    "        'kermanshah': 'Kermanshah',\n",
    "        'Kohkiloyeh': 'Kohgiluyeh and Boyer-Ahmad',\n",
    "        'Golestan': 'Golestan',\n",
    "        'Gilan': 'Gilan',\n",
    "        'Lorestan': 'Lorestan',\n",
    "        'Babol': 'Mazandaran',\n",
    "        'Mazandaran': 'Mazandaran',\n",
    "        'Arak': 'Markazi',\n",
    "        'saveh': 'Markazi',\n",
    "        'Hormozgan': 'Hormozgan',\n",
    "        'Hamedan': 'Hamedan',\n",
    "        'Yazd': 'Yazd'\n",
    "    },\n",
    "    'caspian_V_new':{\n",
    "        'charmahal': 'Chaharmahal and Bakhtiari',\n",
    "        'alborz': 'Alborz',\n",
    "        'dezful': 'Khuzestan',\n",
    "        'mazandaran': 'Mazandaran',\n",
    "        'sabzevar': 'Razavi Khorasan',\n",
    "        'azar gharbi': 'West Azerbaijan',\n",
    "        'kurdestan': 'Kurdistan',\n",
    "        'kerman.jiroft': 'Kerman',\n",
    "        'ardebil': 'Ardabil',\n",
    "        'hamedan': 'Hamedan',\n",
    "        'khorasan shomali': 'South Khorasan',\n",
    "        'ilam': 'Ilam',\n",
    "        'khozestan': 'Khuzestan',\n",
    "        'shoshtar': 'Khuzestan',\n",
    "        'qazvin': 'Qazvin',\n",
    "        'isfahan': 'Isfahan',\n",
    "        'gilan': 'Gilan',\n",
    "        'tabriz': 'East Azerbaijan',\n",
    "        'arak': 'Markazi',\n",
    "        'semnan': 'Semnan',\n",
    "        'hormozgan': 'Hormozgan',\n",
    "        'lorestan': 'Lorestan',\n",
    "        'boshehr': 'Bushehr',\n",
    "        'zanjan': 'Zanjan',\n",
    "        'sistan': 'Sistan and Baluchestan',\n",
    "        'kermanshah': 'Kermanshah',\n",
    "        'fars': 'Fars',\n",
    "        'torbat heidariyeh': 'Razavi Khorasan',\n",
    "        'kerman': 'Kerman',\n",
    "        'khorasan jonobi': 'North Khorasan',\n",
    "        'yazd': 'Yazd',\n",
    "        'golestan': 'Golestan',\n",
    "        'behbahan': 'Khuzestan',\n",
    "        'shahidbeheshti': 'Tehran',\n",
    "        'shahrood': 'Semnan',\n",
    "        'khorasan razavi': 'Razavi Khorasan',\n",
    "        'saveh': 'Markazi',\n",
    "        'iran': 'General Iran',\n",
    "        'esfarayen': 'North Khorasan',\n",
    "        'kohkiloyeh': 'Kohgiluyeh and Boyer-Ahmad',\n",
    "        'abadan': 'Khuzestan',\n",
    "        'rafsanjan': 'Kerman',\n",
    "        'iranshahr': 'Sistan and Baluchestan',\n",
    "        'babol': 'Mazandaran',\n",
    "        'torbat jam': 'Razavi Khorasan',\n",
    "        'zabol': 'Sistan and Baluchestan',\n",
    "        'kashan': 'Isfahan',\n",
    "        'jahrom': 'Fars',\n",
    "        'neishabor': 'Razavi Khorasan',\n",
    "        'bam': 'Kerman',\n",
    "        'tehran': 'Tehran',\n",
    "        'larestan': 'Fars',\n",
    "        'fasad': 'Fars'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply the function to the entire dictionary\n",
    "# processed_dfs = replacement_function(processed_dfs, mappings)\n",
    "university_to_province = mappings.get('caspian_IV')\n",
    "processed_dfs['caspian_IV']['university'] = processed_dfs['caspian_IV']['university'].replace(university_to_province)\n",
    "                \n",
    "# Ensure the 'university' column is of type string\n",
    "processed_dfs['caspian_IV']['university'] = processed_dfs['caspian_IV']['university'].astype(str)\n",
    "\n",
    "# Sort the DataFrame by the 'university' column\n",
    "processed_dfs['caspian_IV'] = processed_dfs['caspian_IV'].sort_values(by='university', ascending=True)\n",
    "\n",
    "university_to_province = mappings.get('caspian_V')\n",
    "processed_dfs['caspian_V']['university'] = processed_dfs['caspian_V']['university'].replace(university_to_province)\n",
    "                \n",
    "# Ensure the 'university' column is of type string\n",
    "processed_dfs['caspian_V']['university'] = processed_dfs['caspian_V']['university'].astype(str)\n",
    "\n",
    "# Sort the DataFrame by the 'university' column\n",
    "processed_dfs['caspian_V'] = processed_dfs['caspian_V'].sort_values(by='university', ascending=True)\n",
    "\n",
    "university_to_province = mappings.get('caspian_IV_prev')\n",
    "processed_dfs['caspian_IV_prev']['university'] = processed_dfs['caspian_IV_prev']['university'].replace(university_to_province)\n",
    "           \n",
    "# Ensure the 'university' column is of type string\n",
    "processed_dfs['caspian_IV_prev']['university'] = processed_dfs['caspian_IV_prev']['university'].astype(str)\n",
    "\n",
    "# Sort the DataFrame by the 'university' column\n",
    "processed_dfs['caspian_IV_prev'] = processed_dfs['caspian_IV_prev'].sort_values(by='university', ascending=True)\n",
    "\n",
    "university_to_province = mappings.get('caspian_V_new')\n",
    "processed_dfs['caspian_V_new']['university'] = processed_dfs['caspian_V_new']['university'].replace(university_to_province)\n",
    "           \n",
    "# Ensure the 'university' column is of type string\n",
    "processed_dfs['caspian_V_new']['university'] = processed_dfs['caspian_V_new']['university'].astype(str)\n",
    "\n",
    "# Sort the DataFrame by the 'university' column\n",
    "processed_dfs['caspian_V_new'] = processed_dfs['caspian_V_new'].sort_values(by='university', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Merging two dataset based on matching_features for finding similar records between two dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=processed_dfs['caspian_IV_prev']\n",
    "df2=processed_dfs['caspian_V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ap_3'] = df1['ap_3'].str.lower()\n",
    "df1['ap_4'] = df1['ap_4'].str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'university': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'a_1': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'a_2': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'a_3': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'a_4': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'ap_2': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'ap_3': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()},\n",
       " 'ap_4': {'are_equal': True, 'only_in_df1': set(), 'only_in_df2': set()}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of features to compare\n",
    "features = ['university','a_1', 'a_2', 'a_3', 'a_4', 'ap_2', 'ap_3', 'ap_4']  # Add your feature names here\n",
    "\n",
    "# Dictionary to store results\n",
    "comparison_results = {}\n",
    "\n",
    "for feature in features:\n",
    "    # Sort and convert unique values of the feature in each dataframe\n",
    "    df1_unique_sorted = sorted(df1[feature].unique(), key=str)\n",
    "    df2_unique_sorted = sorted(df2[feature].unique(), key=str)\n",
    "    \n",
    "    # Convert to sets\n",
    "    df1_unique_set = set(df1_unique_sorted)\n",
    "    df2_unique_set = set(df2_unique_sorted)\n",
    "    \n",
    "    # Find differences\n",
    "    only_in_df1 = df1_unique_set - df2_unique_set\n",
    "    only_in_df2 = df2_unique_set - df1_unique_set\n",
    "    \n",
    "    # Check equality and store results\n",
    "    are_equal = not only_in_df1 and not only_in_df2\n",
    "    comparison_results[feature] = {\n",
    "        \"are_equal\": are_equal,\n",
    "        \"only_in_df1\": only_in_df1,\n",
    "        \"only_in_df2\": only_in_df2\n",
    "    }\n",
    "\n",
    "# Print comparison results\n",
    "comparison_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40 entries, 12333 to 2741\n",
      "Columns: 507 entries, id2 to bmi1\n",
      "dtypes: category(333), float64(170), object(4)\n",
      "memory usage: 124.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  feature columns to match on\n",
    "matching_features = ['cluster','sample_c','age', 'weight', 'height', 'university', 'region', 'wrist4', 'waist_3', 'systolic', \n",
    "                     'a_1', 'a_2', 'a_3', 'a_4', 'ap_2', 'ap_3', 'ap_4', 'familynu', 'birth_ye']\n",
    "# Merge the datasets on matching features\n",
    "merged_df = pd.merge(df1, df2, on=matching_features, suffixes=('_df1', '_df2'))\n",
    "\n",
    "# Group by 'id2' from df2 and collect 'id2' values from df1\n",
    "result = merged_df.groupby('id2_df2')['id2_df1'].apply(list).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "result.columns = ['record_id2_df2', 'records_id2_df1']\n",
    "\n",
    "\n",
    "# Step 1: Flatten the list of `id2` values from `records_id2_df1`\n",
    "id2_to_remove = set([item for sublist in result['records_id2_df1'] for item in sublist])\n",
    "\n",
    "# Step 2: Filter `caspian_IV` to exclude these `id2` values\n",
    "df_filtered = df1[~df1['id2'].isin(id2_to_remove)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(df_filtered.info())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>save intersection ids between 2 datasets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = 'intersection_data_4_prev&5.xlsx'\n",
    "with pd.ExcelWriter(output_file) as writer:\n",
    "    result.to_excel(writer, index=False, sheet_name='ID2 Intersections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save new dataset that similar records deleted from it</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadstat\n",
    "# Save df_iv to a new SPSS file after modifications\n",
    "pyreadstat.write_sav(df_filtered, 'data/caspian4_modified.sav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save new dataset that similar records deleted from it with matching feature column</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyreadstat\n",
    "\n",
    "matching_features = ['id2','cluster','sample_c','age', 'weight', 'height', 'university', 'region', 'wrist4', 'waist_3', 'systolic', \n",
    "                     'a_1', 'a_2', 'a_3', 'a_4', 'ap_2', 'ap_3', 'ap_4', 'familynu', 'birth_ye']\n",
    "# Save df_iv to a new SPSS file after modifications\n",
    "pyreadstat.write_sav(df_filtered[matching_features], 'data/selected_col/modified-caspian4_selected-col.sav')\n",
    "pyreadstat.write_sav(df2[matching_features], 'data/selected_col/caspian5_selected-col.sav')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CASPIAN_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
